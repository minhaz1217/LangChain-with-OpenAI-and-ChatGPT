{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "envKey = \"OPENAI_API_KEY\"\n",
    "\n",
    "# clearing the key if exists\n",
    "if os.getenv(envKey) != None:\n",
    "    os.environ.pop(envKey) # this is only needed if the environment got set by accident and we want to clear it\n",
    "\n",
    "# loading the environment variable from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_chroma  import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "loader = TextLoader(\"./conversation.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='The United States Capitol\\n\\nMr. Speaker. Madam Vice President. Our First Lady and Second Gentleman.\\n\\nMembers of Congress and the Cabinet. Leaders of our military.\\n\\nMr. Chief Justice, Associate Justices, and retired Justices of the Supreme Court.\\n\\nAnd you, my fellow Americans.\\n\\nI start tonight by congratulating the members of the 118th Congress and the new Speaker of the House, Kevin McCarthy.\\n\\nMr. Speaker, I look forward to working together.\\n\\nI also want to congratulate the new leader of the House Democrats and the first Black House Minority Leader in history, Hakeem Jeffries.\\n\\nCongratulations to the longest serving Senate Leader in history, Mitch McConnell.\\n\\nAnd congratulations to Chuck Schumer for another term as Senate Majority Leader, this time with an even bigger majority.\\n\\nAnd I want to give special recognition to someone who I think will be considered the greatest Speaker in the history of this country, Nancy Pelosi.' metadata={'source': './conversation.txt'}\n"
     ]
    }
   ],
   "source": [
    "textSplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = textSplitter.split_documents(documents)\n",
    "\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "store = Chroma.from_documents(texts, embeddings, collection_name=\"state-of-the-union\")\n",
    "\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# vectorstore = Chroma.from_documents(documents=texts, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k is the number of chunks to retrieve\n",
    "# retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "# docs = retriever.invoke(\"Can LangSmith help test my LLM applications?\")\n",
    "\n",
    "# # docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import create_qa_with_sources_chain\n",
    "# from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "# chain1 = RetrievalQA(retriever=store.as_retriever())\n",
    "# # chain2 = ConversationalRetrievalChain.from_llm(llm, store.as_retriever())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have a record number of personnel working to secure the border, arresting 8,000 human smugglers and seizing over 23,000 pounds of fentanyl in just the last several months.\n",
      "\n",
      "Since we launched our new border plan last month, unlawful migration from Cuba, Haiti, Nicaragua, and Venezuela has come down 97%.\n",
      "\n",
      "But Americaâ€™s border problems wonâ€™t be fixed until Congress acts.\n",
      "\n",
      "If you wonâ€™t pass my comprehensive immigration reform, at least pass my plan to provide the equipment and officers to secure the border. And a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers.\n",
      "\n",
      "Here in the peopleâ€™s House, itâ€™s our duty to protect all the peopleâ€™s rights and freedoms.\n",
      "\n",
      "Congress must restore the right the Supreme Court took away last year and codify Roe v. Wade to protect every womanâ€™s constitutional right to choose.\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(texts, embedding_function)\n",
    "\n",
    "# query it\n",
    "query = \"What did the president say about mexico\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# print results\n",
    "print(docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
